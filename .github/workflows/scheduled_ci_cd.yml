name: Scheduled CI/CD

on:
  schedule:
    - cron: "0 11 * * *"

jobs:
  check-and-deploy:
    environment: prd
    runs-on: ubuntu-latest

    env:
      AWS_ACCESS_KEY_ID: ${{secrets.AWS_ACCESS_KEY_ID}}
      AWS_SECRET: ${{secrets.AWS_SECRET}}
      AWS_S3_BUCKET: ${{secrets.AWS_S3_BUCKET}}
      AWS_S3_TST_BUCKET: ${{secrets.AWS_S3_TST_BUCKET}}
      POLYGON_API_KEY: ${{secrets.POLYGON_API_KEY}}
      FINNHUB_API_KEY: ${{secrets.FINNHUB_API_KEY}}
      NEWS_API_KEY: ${{secrets.NEWS_API_KEY}}
      REDDIT_CLIENT_ID: ${{secrets.REDDIT_CLIENT_ID}}
      REDDIT_CLIENT_SECRET: ${{secrets.REDDIT_CLIENT_SECRET}}
      REDDIT_USER_AGENT: ${{secrets.REDDIT_USER_AGENT}}
      REDDIT_USERNAME: ${{secrets.REDDIT_USERNAME}}
      REDDIT_PASSWORD: ${{secrets.REDDIT_PASSWORD}}
      SNOWFLAKE_USER: ${{secrets.SNOWFLAKE_USER}}
      SNOWFLAKE_PASSWORD: ${{secrets.SNOWFLAKE_PASSWORD}}
      SNOWFLAKE_ACCOUNT: ${{secrets.SNOWFLAKE_ACCOUNT}}
      FRED_API_KEY: ${{secrets.FRED_API_KEY}}
      SEC_API_USER_AGENT: ${{secrets.SEC_API_USER_AGENT}}
      SNOWFLAKE_PRIVATE_KEY_B64: ${{secrets.SNOWFLAKE_PRIVATE_KEY_B64}}
      SNOWFLAKE_PRIVATE_KEY_PASSPHRASE: ${{secrets.SNOWFLAKE_PRIVATE_KEY_PASSPHRASE}}
      KAFKA_BOOTSTRAP_SERVERS_TST: ${{secrets.KAFKA_BOOTSTRAP_SERVERS_TST}}
      KAFKA_TOPIC_TST: ${{secrets.KAFKA_TOPIC_TST}}
      SCHEMA_REGISTRY_URL_TST: ${{secrets.SCHEMA_REGISTRY_URL_TST}}
      METABASE_PRIVATE_KEY: ${{secrets.METABASE_PRIVATE_KEY}}
      TF_VAR_aws_access_key_id: ${{secrets.AWS_ACCESS_KEY_ID}}
      TF_VAR_aws_secret: ${{secrets.AWS_SECRET}}
      TF_VAR_aws_s3_bucket: ${{secrets.AWS_S3_BUCKET}}
      TF_VAR_aws_s3_tst_bucket: ${{secrets.AWS_S3_TST_BUCKET}}
      TF_VAR_airflow_uid: ${{secrets.TF_AIRFLOW_UID}}
      TF_VAR_polygon_api_key: ${{secrets.POLYGON_API_KEY}}
      TF_VAR_finnhub_api_key: ${{secrets.FINNHUB_API_KEY}}
      TF_VAR_news_api_key: ${{secrets.NEWS_API_KEY}}
      TF_VAR_reddit_client_id: ${{secrets.REDDIT_CLIENT_ID}}
      TF_VAR_reddit_client_secret: ${{secrets.REDDIT_CLIENT_SECRET}}
      TF_VAR_reddit_user_agent: ${{secrets.REDDIT_USER_AGENT}}
      TF_VAR_reddit_username: ${{secrets.REDDIT_USERNAME}}
      TF_VAR_reddit_password: ${{secrets.REDDIT_PASSWORD}}
      TF_VAR_snowflake_user: ${{secrets.SNOWFLAKE_USER}}
      TF_VAR_snowflake_password: ${{secrets.SNOWFLAKE_PASSWORD}}
      TF_VAR_snowflake_account: ${{secrets.SNOWFLAKE_ACCOUNT}}
      TF_VAR_fred_api_key: ${{secrets.FRED_API_KEY}}
      TF_VAR_sec_api_user_agent: ${{secrets.SEC_API_USER_AGENT}}
      TF_VAR_snowflake_private_key_b64: ${{secrets.SNOWFLAKE_PRIVATE_KEY_B64}}
      TF_VAR_snowflake_private_key_passphrase: ${{secrets.SNOWFLAKE_PRIVATE_KEY_PASSPHRASE}}
      TF_VAR_kafka_bootstrap_servers: ${{secrets.KAFKA_BOOTSTRAP_SERVERS}}
      TF_VAR_kafka_topic: ${{secrets.KAFKA_TOPIC}}
      TF_VAR_schema_registry_url: ${{secrets.SCHEMA_REGISTRY_URL}}
      TF_VAR_metabase_private_key: ${{secrets.METABASE_PRIVATE_KEY}}

    steps:
      - name: Download push marker
        uses: actions/download-artifact@v4
        with:
          name: main-updated-flag
        continue-on-error: true

      - name: Exit if no new push
        run: |
          if [ ! -f push_flag.txt ]; then
            echo "No new code since last build. Exiting."
            exit 0
          fi

      - name: Remove marker (reset for next cycle)
        run: rm push_flag.txt
      
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Set up Docker Compose
        run: sudo apt-get update && sudo apt-get install -y docker-compose
      
      - name: Start services with docker-compose
        working-directory: ./airflow/dags/tests
        run: docker-compose -f docker-compose-integration.yml up -d
      
      - name: Wait for services
        run: |
          echo "Waiting for containers..."
          sleep 90
          docker ps

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Run tests
        run: |
          pytest airflow/dags/tests
      
      - name: Stop integration services
        if: always()
        working-directory: ./airflow/dags/tests
        run: docker-compose -f docker-compose-integration.yml down

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v3

      - name: Terraform Init
        run: terraform init

      - name: Terraform Plan
        run: terraform plan -out=tfplan

      - name: Terraform Apply
        run: terraform apply -auto-approve tfplan
