name: Scheduled CI/CD

on:
  push:
    branches:
      - main
  workflow_dispatch:

jobs:
  check-and-deploy:
    environment: prd
    runs-on: ubuntu-latest

    defaults:
      run:
        working-directory: ./infrastructure

    env:
      AWS_ACCESS_KEY_ID: ${{secrets.AWS_ACCESS_KEY_ID}}
      AWS_SECRET_ACCESS_KEY: ${{secrets.AWS_SECRET_ACCESS_KEY}}
      AWS_REGION: ${{secrets.AWS_REGION}}
      AWS_S3_BUCKET: ${{secrets.AWS_S3_BUCKET}}
      AWS_S3_TST_BUCKET: ${{secrets.AWS_S3_TST_BUCKET}}
      POLYGON_API_KEY: ${{secrets.POLYGON_API_KEY}}
      FINNHUB_API_KEY: ${{secrets.FINNHUB_API_KEY}}
      NEWS_API_KEY: ${{secrets.NEWS_API_KEY}}
      REDDIT_CLIENT_ID: ${{secrets.REDDIT_CLIENT_ID}}
      REDDIT_CLIENT_SECRET: ${{secrets.REDDIT_CLIENT_SECRET}}
      REDDIT_USER_AGENT: ${{secrets.REDDIT_USER_AGENT}}
      REDDIT_USERNAME: ${{secrets.REDDIT_USERNAME}}
      REDDIT_PASSWORD: ${{secrets.REDDIT_PASSWORD}}
      SNOWFLAKE_USER: ${{secrets.SNOWFLAKE_USER}}
      SNOWFLAKE_PASSWORD: ${{secrets.SNOWFLAKE_PASSWORD}}
      SNOWFLAKE_ACCOUNT: ${{secrets.SNOWFLAKE_ACCOUNT}}
      SNOWFLAKE_ROLE: ${{secrets.SNOWFLAKE_ROLE}}
      FRED_API_KEY: ${{secrets.FRED_API_KEY}}
      SEC_API_USER_AGENT: ${{secrets.SEC_API_USER_AGENT}}
      SNOWFLAKE_PRIVATE_KEY_B64: ${{secrets.SNOWFLAKE_PRIVATE_KEY_B64}}
      SNOWFLAKE_PRIVATE_KEY_PASSPHRASE: ${{secrets.SNOWFLAKE_PRIVATE_KEY_PASSPHRASE}}
      KAFKA_BOOTSTRAP_SERVERS_TST: ${{secrets.KAFKA_BOOTSTRAP_SERVERS_TST}}
      KAFKA_TOPIC_TST: ${{secrets.KAFKA_TOPIC_TST}}
      SCHEMA_REGISTRY_URL_TST: ${{secrets.SCHEMA_REGISTRY_URL_TST}}
      METABASE_PRIVATE_KEY: ${{secrets.METABASE_PRIVATE_KEY}}
      POSTGRES_USERNAME: ${{secrets.POSTGRES_USERNAME}}
      POSTGRES_PASSWORD: ${{secrets.POSTGRES_PASSWORD}}
      DOMAIN_NAME: ${{secrets.DOMAIN_NAME}}
      CERTBOT_EMAIL: ${{secrets.CERTBOT_EMAIL}}
      TF_VAR_aws_access_key_id: ${{secrets.AWS_ACCESS_KEY_ID}}
      TF_VAR_aws_secret_access_key: ${{secrets.AWS_SECRET_ACCESS_KEY}}
      TF_VAR_aws_s3_bucket: ${{secrets.AWS_S3_BUCKET}}
      TF_VAR_aws_s3_tst_bucket: ${{secrets.AWS_S3_TST_BUCKET}}
      TF_VAR_airflow_uid: ${{secrets.AIRFLOW_UID}}
      TF_VAR_airflow_username: ${{secrets.AIRFLOW_USERNAME}}
      TF_VAR_airflow_password: ${{secrets.AIRFLOW_PASSWORD}}
      TF_VAR_airflow_fernet_key: ${{secrets.AIRFLOW_FERNET_KEY}}
      TF_VAR_airflow_email: ${{secrets.AIRFLOW_EMAIL}}
      TF_VAR_polygon_api_key: ${{secrets.POLYGON_API_KEY}}
      TF_VAR_finnhub_api_key: ${{secrets.FINNHUB_API_KEY}}
      TF_VAR_news_api_key: ${{secrets.NEWS_API_KEY}}
      TF_VAR_reddit_client_id: ${{secrets.REDDIT_CLIENT_ID}}
      TF_VAR_reddit_client_secret: ${{secrets.REDDIT_CLIENT_SECRET}}
      TF_VAR_reddit_user_agent: ${{secrets.REDDIT_USER_AGENT}}
      TF_VAR_reddit_username: ${{secrets.REDDIT_USERNAME}}
      TF_VAR_reddit_password: ${{secrets.REDDIT_PASSWORD}}
      TF_VAR_snowflake_user: ${{secrets.SNOWFLAKE_USER}}
      TF_VAR_snowflake_password: ${{secrets.SNOWFLAKE_PASSWORD}}
      TF_VAR_snowflake_account: ${{secrets.SNOWFLAKE_ACCOUNT}}
      TF_VAR_snowflake_role: ${{secrets.SNOWFLAKE_ROLE}}
      TF_VAR_fred_api_key: ${{secrets.FRED_API_KEY}}
      TF_VAR_sec_api_user_agent: ${{secrets.SEC_API_USER_AGENT}}
      TF_VAR_snowflake_private_key_b64: ${{secrets.SNOWFLAKE_PRIVATE_KEY_B64}}
      TF_VAR_snowflake_private_key_passphrase: ${{secrets.SNOWFLAKE_PRIVATE_KEY_PASSPHRASE}}
      TF_VAR_kafka_bootstrap_servers: ${{secrets.KAFKA_BOOTSTRAP_SERVERS}}
      TF_VAR_kafka_topic: ${{secrets.KAFKA_TOPIC}}
      TF_VAR_schema_registry_url: ${{secrets.SCHEMA_REGISTRY_URL}}
      TF_VAR_metabase_private_key: ${{secrets.METABASE_PRIVATE_KEY}}
      TF_VAR_postgres_username: ${{secrets.POSTGRES_USERNAME}}
      TF_VAR_postgres_password: ${{secrets.POSTGRES_PASSWORD}}
      TF_VAR_domain_name: ${{secrets.DOMAIN_NAME}}
      TF_VAR_certbot_email: ${{secrets.CERTBOT_EMAIL}}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        working-directory: .
        run: pip install -r requirements.txt
      
      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v3

      - name: Terraform Init
        run: terraform init

      - name: Terraform Plan
        run: terraform plan -out=tfplan

      - name: Terraform Apply
        run: terraform apply -auto-approve tfplan
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Install Docker Compose
        run: sudo apt-get update && sudo apt-get install -y docker-compose
      
      - name: Start services with docker-compose
        working-directory: ./airflow/dags/tests
        run: docker-compose -f docker-compose-integration.yml up -d
      
      - name: Wait for services
        run: |
          echo "Waiting for containers..."
          sleep 300
      
      - name: Create kafka topic for testing
        working-directory: ./airflow/dags/tests
        run: docker exec tests_kafka-1_1 kafka-topics --bootstrap-server kafka-1:9092 --create --topic stock_aggregates_tst --partitions 1 --replication-factor 1
      
      - name: Create kafka Snowflake connection for testing
        working-directory: ./airflow/dags/tests
        run: |
          curl -X POST -H 'Content-Type: application/json' --data @connector.json http://localhost:8083/connectors
      
      - name: Run tests
        working-directory: .
        run: pytest airflow/dags/tests -vv
      
      - name: Stop integration services
        working-directory: ./airflow/dags/tests
        run: docker-compose -f docker-compose-integration.yml down
      
      - name: Get EC2 instance ID
        run: |
          INSTANCE_ID=$(terraform output -raw ssm_instance_id)
          echo "INSTANCE_ID=$INSTANCE_ID" >> $GITHUB_ENV
      
      - name: Deploy to EC2 via SSM
        run: |
          set -e

          COMMAND_ID=$(aws ssm send-command \
            --region "$AWS_REGION" \
            --instance-ids "$INSTANCE_ID" \
            --document-name "AWS-RunShellScript" \
            --comment "Full deployment" \
            --timeout-seconds 3600 \
            --max-concurrency "1" \
            --max-errors "0" \
            --parameters '{
              "commands": [
                "if [ -d Investment-Analytics-Data-Warehouse/.git ]; then cd Investment-Analytics-Data-Warehouse && git fetch origin && git checkout dev && git pull origin dev; else git clone --branch dev https://github.com/jacobpalinski/Investment-Analytics-Data-Warehouse.git; cd Investment-Analytics-Data-Warehouse; fi",
                "chmod +x deploy.sh",
                "./deploy.sh"
              ]
            }' \
            --query "Command.CommandId" \
            --output text)

          echo "SSM Command ID: $COMMAND_ID"

          echo "Waiting for command to finish..."
          while true; do
            STATUS=$(aws ssm get-command-invocation \
              --region "$AWS_REGION" \
              --command-id "$COMMAND_ID" \
              --instance-id "$INSTANCE_ID" \
              --query "Status" \
              --output text)

            echo "Current SSM status: $STATUS"

            case "$STATUS" in
              Pending|InProgress|Delayed)
                sleep 30
                ;;
              Success)
                echo "Deployment completed successfully"
                break
                ;;
              Failed|Cancelled|TimedOut)
                echo "Deployment failed on EC2"
                aws ssm get-command-invocation \
                  --region "$AWS_REGION" \
                  --command-id "$COMMAND_ID" \
                  --instance-id "$INSTANCE_ID" \
                  --query "StandardErrorContent" \
                  --output text
                exit 1
                ;;
              *)
                echo "Unknown SSM status: $STATUS"
                exit 1
                ;;
            esac
          done




      







      